{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480acc89",
   "metadata": {},
   "source": [
    "# Clinical Trials Prediction Market Generator\n",
    "\n",
    "This notebook fetches behavioral intervention studies from ClinicalTrials.gov and generates prediction market questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef251a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import json\n",
    "import csv\n",
    "from typing import Dict, List, Optional, Generator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a8875",
   "metadata": {},
   "source": [
    "## API Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280a14f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API functions loaded âœ…\n"
     ]
    }
   ],
   "source": [
    "def fetch_studies(page_size: int = 100, max_pages: int = 5, sleep_sec: float = 0.1) -> Generator[Dict, None, None]:\n",
    "    \"\"\"\n",
    "    Fetch behavioral intervention studies from ClinicalTrials.gov API\n",
    "    \"\"\"\n",
    "    BASE = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "    \n",
    "    fields = [\n",
    "        \"protocolSection.identificationModule.nctId\",\n",
    "        \"protocolSection.identificationModule.briefTitle\",\n",
    "        \"protocolSection.outcomesModule.primaryOutcomes\",\n",
    "        \"protocolSection.conditionsModule.conditions\",\n",
    "        \"protocolSection.armsInterventionsModule.interventions\",\n",
    "        \"protocolSection.statusModule.overallStatus\",\n",
    "        \"protocolSection.statusModule.whyStopped\",\n",
    "        \"hasResults\",\n",
    "        \"resultsSection.outcomeMeasuresModule.outcomeMeasures\"\n",
    "    ]\n",
    "    \n",
    "    query = \"AREA[InterventionType]BEHAVIORAL\"\n",
    "    next_page_token = None\n",
    "    \n",
    "    for page in range(max_pages):\n",
    "        params = {\n",
    "            \"pageSize\": page_size,\n",
    "            \"query.term\": query,\n",
    "            \"fields\": \",\".join(fields)\n",
    "        }\n",
    "        \n",
    "        if next_page_token:\n",
    "            params[\"pageToken\"] = next_page_token\n",
    "        \n",
    "        full_url = f\"{BASE}?{urllib.parse.urlencode(params)}\"\n",
    "        \n",
    "        req = urllib.request.Request(full_url)\n",
    "        req.add_header('User-Agent', 'Python-urllib/3.11')\n",
    "        req.add_header('Accept', 'application/json')\n",
    "        \n",
    "        try:\n",
    "            with urllib.request.urlopen(req, timeout=30) as response:\n",
    "                if response.status != 200:\n",
    "                    break\n",
    "                \n",
    "                data = json.loads(response.read().decode())\n",
    "                studies = data.get('studies', [])\n",
    "                \n",
    "                if not studies:\n",
    "                    break\n",
    "                \n",
    "                for study in studies:\n",
    "                    yield study\n",
    "                \n",
    "                next_page_token = data.get('nextPageToken')\n",
    "                if not next_page_token or len(studies) < page_size:\n",
    "                    break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching page {page}: {e}\")\n",
    "            break\n",
    "        \n",
    "        if sleep_sec > 0:\n",
    "            import time\n",
    "            time.sleep(sleep_sec)\n",
    "\n",
    "print(\"API functions loaded âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b025b3d",
   "metadata": {},
   "source": [
    "## Success Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125f54a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success assessment function loaded âœ…\n"
     ]
    }
   ],
   "source": [
    "def assess_study_success(study_data: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Comprehensive assessment of intervention success based on actual results data.\n",
    "    Combines statistical analysis with fallback to study status assessment.\n",
    "    \"\"\"\n",
    "    protocol_section = study_data.get('protocolSection', {})\n",
    "    status_module = protocol_section.get('statusModule', {})\n",
    "    \n",
    "    overall_status = status_module.get('overallStatus', '')\n",
    "    why_stopped = status_module.get('whyStopped', '')\n",
    "    has_results = study_data.get('hasResults', False)\n",
    "    \n",
    "    # First, try to analyze actual intervention results if available\n",
    "    if has_results and \"resultsSection\" in study_data:\n",
    "        results_analysis = analyze_intervention_results(study_data)\n",
    "        if results_analysis['success'] is not None:\n",
    "            return {\n",
    "                'status': overall_status,\n",
    "                'success': results_analysis['success'],\n",
    "                'confidence': results_analysis['confidence'],\n",
    "                'has_results': has_results,\n",
    "                'termination_reason': why_stopped if why_stopped else None,\n",
    "                'assessment_method': 'statistical_analysis',\n",
    "                'details': results_analysis.get('summary', '')\n",
    "            }\n",
    "    \n",
    "    # Fallback to status-based assessment\n",
    "    assessment = {\n",
    "        'status': overall_status,\n",
    "        'success': 'INCONCLUSIVE',\n",
    "        'confidence': 'low',\n",
    "        'has_results': has_results,\n",
    "        'termination_reason': why_stopped if why_stopped else None,\n",
    "        'assessment_method': 'status_only',\n",
    "        'details': ''\n",
    "    }\n",
    "    \n",
    "    if overall_status == 'COMPLETED':\n",
    "        if has_results:\n",
    "            assessment['success'] = 'COMPLETED_WITH_RESULTS'\n",
    "            assessment['confidence'] = 'medium'\n",
    "            assessment['details'] = 'Study completed and results posted, but detailed analysis unavailable'\n",
    "        else:\n",
    "            assessment['success'] = 'COMPLETED_NO_RESULTS'\n",
    "            assessment['details'] = 'Study completed but no results posted yet'\n",
    "    \n",
    "    elif overall_status == 'TERMINATED' and why_stopped:\n",
    "        why_stopped_lower = why_stopped.lower()\n",
    "        \n",
    "        success_terms = ['efficacy demonstrated', 'objectives achieved', 'met endpoint']\n",
    "        failure_terms = ['futility', 'lack of efficacy', 'safety concerns', 'ineffective']\n",
    "        \n",
    "        if any(term in why_stopped_lower for term in success_terms):\n",
    "            assessment['success'] = 'SUCCESS'\n",
    "            assessment['confidence'] = 'high'\n",
    "            assessment['details'] = f'Terminated early for success: {why_stopped}'\n",
    "        elif any(term in why_stopped_lower for term in failure_terms):\n",
    "            assessment['success'] = 'FAILURE' \n",
    "            assessment['confidence'] = 'high'\n",
    "            assessment['details'] = f'Terminated early for failure: {why_stopped}'\n",
    "        else:\n",
    "            assessment['success'] = 'TERMINATED_UNCLEAR'\n",
    "            assessment['confidence'] = 'medium'\n",
    "            assessment['details'] = f'Terminated: {why_stopped}'\n",
    "    \n",
    "    elif overall_status in ['ACTIVE_NOT_RECRUITING', 'RECRUITING', 'NOT_YET_RECRUITING']:\n",
    "        assessment['success'] = 'ONGOING'\n",
    "        assessment['confidence'] = 'high'\n",
    "        assessment['details'] = 'Study still in progress'\n",
    "    \n",
    "    elif overall_status == 'WITHDRAWN':\n",
    "        assessment['success'] = 'WITHDRAWN'\n",
    "        assessment['confidence'] = 'high'\n",
    "        assessment['details'] = 'Study withdrawn before completion'\n",
    "    \n",
    "    return assessment\n",
    "\n",
    "\n",
    "def analyze_intervention_results(study_data: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze actual intervention results from ClinicalTrials.gov results data.\n",
    "    Returns statistical assessment of intervention success.\n",
    "    \"\"\"\n",
    "    if not study_data.get(\"hasResults\") or \"resultsSection\" not in study_data:\n",
    "        return {\"success\": None, \"confidence\": \"unknown\", \"summary\": \"No results available\"}\n",
    "    \n",
    "    results = []\n",
    "    outcome_measures = study_data[\"resultsSection\"].get(\"outcomeMeasuresModule\", {}).get(\"outcomeMeasures\", [])\n",
    "    \n",
    "    # Focus on primary outcomes first\n",
    "    primary_outcomes = [om for om in outcome_measures if om.get(\"type\") == \"PRIMARY\"]\n",
    "    if not primary_outcomes:\n",
    "        primary_outcomes = outcome_measures[:3]  # Take first few if no primary outcomes\n",
    "    \n",
    "    for outcome in primary_outcomes:\n",
    "        title = outcome.get(\"title\", \"Unknown outcome\")\n",
    "        unit = outcome.get(\"unitOfMeasure\", \"\")\n",
    "        \n",
    "        # Method 1: Check statistical analyses (most reliable)\n",
    "        analyses = outcome.get(\"analyses\", [])\n",
    "        has_statistical_analysis = False\n",
    "        \n",
    "        for analysis in analyses:\n",
    "            has_statistical_analysis = True\n",
    "            p_value = analysis.get(\"pValue\")\n",
    "            param_value = analysis.get(\"paramValue\")\n",
    "            ci_lower = analysis.get(\"ciLowerLimit\")\n",
    "            ci_upper = analysis.get(\"ciUpperLimit\")\n",
    "            \n",
    "            is_significant = False\n",
    "            confidence = \"low\"\n",
    "            \n",
    "            if p_value:\n",
    "                try:\n",
    "                    # Handle p-values like \".001\" or \"0.001\"\n",
    "                    p_val = float(p_value.replace('.', '0.') if p_value.startswith('.') else p_value)\n",
    "                    is_significant = p_val < 0.05\n",
    "                    confidence = \"high\" if p_val < 0.001 else \"medium\" if p_val < 0.01 else \"low\"\n",
    "                except (ValueError, TypeError):\n",
    "                    pass\n",
    "            \n",
    "            # Check if confidence interval excludes null effect\n",
    "            ci_excludes_null = False\n",
    "            if ci_lower and ci_upper:\n",
    "                try:\n",
    "                    lower = float(ci_lower)\n",
    "                    upper = float(ci_upper)\n",
    "                    # For most outcomes, null effect is 0 (no change)\n",
    "                    if (lower > 0 and upper > 0) or (lower < 0 and upper < 0):\n",
    "                        ci_excludes_null = True\n",
    "                except (ValueError, TypeError):\n",
    "                    pass\n",
    "            \n",
    "            results.append({\n",
    "                \"outcome\": title,\n",
    "                \"method\": \"statistical_analysis\",\n",
    "                \"p_value\": p_value,\n",
    "                \"effect_size\": param_value,\n",
    "                \"is_significant\": is_significant,\n",
    "                \"ci_excludes_null\": ci_excludes_null,\n",
    "                \"confidence\": confidence,\n",
    "                \"unit\": unit\n",
    "            })\n",
    "        \n",
    "        # Method 2: If no statistical analysis, look at raw measurements  \n",
    "        if not has_statistical_analysis and outcome.get(\"classes\"):\n",
    "            for result_class in outcome[\"classes\"]:\n",
    "                if result_class.get(\"categories\"):\n",
    "                    for category in result_class[\"categories\"]:\n",
    "                        measurements = category.get(\"measurements\", [])\n",
    "                        \n",
    "                        if len(measurements) >= 2:  # Need at least 2 groups to compare\n",
    "                            values = []\n",
    "                            for m in measurements:\n",
    "                                try:\n",
    "                                    val = float(m.get(\"value\", 0))\n",
    "                                    values.append(val)\n",
    "                                except (ValueError, TypeError):\n",
    "                                    continue\n",
    "                            \n",
    "                            if len(values) >= 2:\n",
    "                                # Basic assessment - is there a notable difference?\n",
    "                                diff = abs(values[0] - values[1])\n",
    "                                avg = sum(values) / len(values)\n",
    "                                percent_diff = (diff / abs(avg)) * 100 if avg != 0 else 0\n",
    "                                \n",
    "                                # Heuristic: >20% difference might be meaningful\n",
    "                                is_meaningful = percent_diff > 20\n",
    "                                \n",
    "                                results.append({\n",
    "                                    \"outcome\": title,\n",
    "                                    \"method\": \"measurement_comparison\",\n",
    "                                    \"values\": values,\n",
    "                                    \"percent_difference\": percent_diff,\n",
    "                                    \"is_significant\": is_meaningful,\n",
    "                                    \"confidence\": \"low\",  # Low confidence without proper stats\n",
    "                                    \"unit\": unit\n",
    "                                })\n",
    "                            break  # Only analyze first category\n",
    "                    break  # Only analyze first class\n",
    "    \n",
    "    # Overall assessment\n",
    "    significant_results = [r for r in results if r.get(\"is_significant\")]\n",
    "    \n",
    "    if not results:\n",
    "        return {\"success\": None, \"confidence\": \"unknown\", \"summary\": \"No analyzable outcome measures\"}\n",
    "    \n",
    "    # Success if any primary outcome shows significant positive effect\n",
    "    overall_success = len(significant_results) > 0\n",
    "    \n",
    "    if significant_results:\n",
    "        confidence_scores = {\"high\": 3, \"medium\": 2, \"low\": 1}\n",
    "        overall_confidence = max([r[\"confidence\"] for r in significant_results], key=lambda x: confidence_scores.get(x, 0))\n",
    "    else:\n",
    "        overall_confidence = \"low\"\n",
    "    \n",
    "    return {\n",
    "        \"success\": 'SUCCESS' if overall_success else 'FAILURE',\n",
    "        \"confidence\": overall_confidence,\n",
    "        \"summary\": f\"{len(significant_results)}/{len(results)} primary outcomes significant\",\n",
    "        \"details\": results\n",
    "    }\n",
    "\n",
    "print(\"Success assessment function loaded âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb441b",
   "metadata": {},
   "source": [
    "## Study Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a438fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis function loaded âœ…\n"
     ]
    }
   ],
   "source": [
    "def analyze_study(study: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze a study and return structured data including intervention success assessment\n",
    "    \"\"\"\n",
    "    protocol_section = study.get('protocolSection', {})\n",
    "    identification = protocol_section.get('identificationModule', {})\n",
    "    \n",
    "    nct_id = identification.get('nctId', 'Unknown')\n",
    "    title = identification.get('briefTitle', 'No title available')\n",
    "    \n",
    "    # Get conditions and interventions\n",
    "    conditions = protocol_section.get('conditionsModule', {}).get('conditions', [])\n",
    "    interventions = protocol_section.get('armsInterventionsModule', {}).get('interventions', [])\n",
    "    primary_outcomes = protocol_section.get('outcomesModule', {}).get('primaryOutcomes', [])\n",
    "    \n",
    "    # Find behavioral interventions\n",
    "    behavioral_interventions = [i for i in interventions if i.get('type') == 'BEHAVIORAL']\n",
    "    \n",
    "    # Comprehensive success assessment\n",
    "    assessment = assess_study_success(study)\n",
    "    \n",
    "    # Generate prediction question\n",
    "    prediction_question = None\n",
    "    if primary_outcomes and behavioral_interventions:\n",
    "        intervention_name = behavioral_interventions[0].get('name', 'the intervention')\n",
    "        measure = primary_outcomes[0].get('measure', 'outcomes')\n",
    "        timeframe = primary_outcomes[0].get('timeFrame', 'study completion')\n",
    "        condition_text = ', '.join(conditions) if conditions else 'participants'\n",
    "        prediction_question = f\"Will {intervention_name} improve {measure} at {timeframe} in {condition_text} for trial {nct_id}?\"\n",
    "    \n",
    "    # Determine intervention success category for easier analysis\n",
    "    success_category = 'unknown'\n",
    "    if assessment['success'] in ['SUCCESS']:\n",
    "        success_category = 'success'\n",
    "    elif assessment['success'] in ['FAILURE']:\n",
    "        success_category = 'failure'\n",
    "    elif assessment['success'] in ['COMPLETED_WITH_RESULTS', 'RESULTS_AVAILABLE']:\n",
    "        success_category = 'completed_with_results'\n",
    "    elif assessment['success'] in ['ONGOING', 'ACTIVE', 'RECRUITING']:\n",
    "        success_category = 'ongoing'\n",
    "    elif assessment['success'] in ['WITHDRAWN']:\n",
    "        success_category = 'withdrawn'\n",
    "    else:\n",
    "        success_category = 'inconclusive'\n",
    "    \n",
    "    return {\n",
    "        'nct_id': nct_id,\n",
    "        'title': title,\n",
    "        'conditions': conditions,\n",
    "        'interventions': len(interventions),\n",
    "        'behavioral_interventions': len(behavioral_interventions),\n",
    "        'primary_outcomes': len(primary_outcomes),\n",
    "        'assessment': assessment,\n",
    "        'success_category': success_category,\n",
    "        'prediction_question': prediction_question,\n",
    "        'suitable_for_prediction': bool(prediction_question),\n",
    "        'evidence_url': f\"https://clinicaltrials.gov/study/{nct_id}\"\n",
    "    }\n",
    "\n",
    "print(\"Analysis function loaded âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee0863",
   "metadata": {},
   "source": [
    "## Fetch and Analyze Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf45a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 500 behavioral intervention studies...\n",
      "âœ… Fetched 500 studies\n",
      "\n",
      "Analyzing studies...\n",
      "âœ… Analyzed 500 studies\n",
      "âœ… Fetched 500 studies\n",
      "\n",
      "Analyzing studies...\n",
      "âœ… Analyzed 500 studies\n"
     ]
    }
   ],
   "source": [
    "# Fetch 500 studies (5 pages of 100 each)\n",
    "print(\"Fetching 500 behavioral intervention studies...\")\n",
    "studies = list(fetch_studies(page_size=100, max_pages=5))\n",
    "print(f\"âœ… Fetched {len(studies)} studies\")\n",
    "\n",
    "# Analyze all studies\n",
    "print(\"\\nAnalyzing studies...\")\n",
    "outcomes = [analyze_study(study) for study in studies]\n",
    "print(f\"âœ… Analyzed {len(outcomes)} studies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dac3da",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97ffadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š STUDY ANALYSIS SUMMARY\n",
      "==================================================\n",
      "Total studies: 500\n",
      "Suitable for prediction markets: 497 (99.4%)\n",
      "Studies with results: 47 (9.4%)\n",
      "Studies with statistical analysis: 42 (8.4%)\n",
      "Completed studies: 290 (58.0%)\n",
      "\n",
      "ðŸŽ¯ SUCCESS ASSESSMENT DISTRIBUTION:\n",
      "  â€¢ COMPLETED_NO_RESULTS: 247 (49.4%)\n",
      "  â€¢ ONGOING: 121 (24.2%)\n",
      "  â€¢ INCONCLUSIVE: 66 (13.2%)\n",
      "  â€¢ SUCCESS: 23 (4.6%)\n",
      "  â€¢ FAILURE: 20 (4.0%)\n",
      "  â€¢ TERMINATED_UNCLEAR: 11 (2.2%)\n",
      "  â€¢ WITHDRAWN: 7 (1.4%)\n",
      "  â€¢ COMPLETED_WITH_RESULTS: 5 (1.0%)\n",
      "\n",
      "ðŸ“ˆ INTERVENTION SUCCESS CATEGORIES:\n",
      "  â€¢ inconclusive: 324 (64.8%)\n",
      "  â€¢ ongoing: 121 (24.2%)\n",
      "  â€¢ success: 23 (4.6%)\n",
      "  â€¢ failure: 20 (4.0%)\n",
      "  â€¢ withdrawn: 7 (1.4%)\n",
      "  â€¢ completed_with_results: 5 (1.0%)\n",
      "\n",
      "ðŸ” ASSESSMENT METHOD DISTRIBUTION:\n",
      "  â€¢ status_only: 458 (91.6%)\n",
      "  â€¢ statistical_analysis: 42 (8.4%)\n",
      "\n",
      "âœ… EXAMPLES OF SUCCESSFUL INTERVENTIONS (23 total):\n",
      "1. NCT03099369: Daily Step-based Exercise Using Fitness Monitors for Peripheral Artery Disease...\n",
      "   Assessment: SUCCESS (confidence: low)\n",
      "   Details: 1/1 primary outcomes significant...\n",
      "\n",
      "2. NCT04025229: High Intensity Interval Training in Endometrial Cancer...\n",
      "   Assessment: SUCCESS (confidence: low)\n",
      "   Details: 1/1 primary outcomes significant...\n",
      "\n",
      "3. NCT02944877: HOPE Social Media Intervention for HIV Testing and Studying Social Networks...\n",
      "   Assessment: SUCCESS (confidence: low)\n",
      "   Details: 1/1 primary outcomes significant...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"ðŸ“Š STUDY ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic counts\n",
    "suitable_for_prediction = sum(1 for o in outcomes if o['suitable_for_prediction'])\n",
    "with_results = sum(1 for o in outcomes if o['assessment']['has_results'])\n",
    "completed = sum(1 for o in outcomes if o['assessment']['status'] == 'COMPLETED')\n",
    "statistical_analysis = sum(1 for o in outcomes if o['assessment'].get('assessment_method') == 'statistical_analysis')\n",
    "\n",
    "print(f\"Total studies: {len(outcomes)}\")\n",
    "print(f\"Suitable for prediction markets: {suitable_for_prediction} ({suitable_for_prediction/len(outcomes)*100:.1f}%)\")\n",
    "print(f\"Studies with results: {with_results} ({with_results/len(outcomes)*100:.1f}%)\")\n",
    "print(f\"Studies with statistical analysis: {statistical_analysis} ({statistical_analysis/len(outcomes)*100:.1f}%)\")\n",
    "print(f\"Completed studies: {completed} ({completed/len(outcomes)*100:.1f}%)\")\n",
    "\n",
    "# Success assessment distribution\n",
    "print(\"\\nðŸŽ¯ SUCCESS ASSESSMENT DISTRIBUTION:\")\n",
    "success_counts = Counter(o['assessment']['success'] for o in outcomes)\n",
    "for success_type, count in success_counts.most_common():\n",
    "    print(f\"  â€¢ {success_type}: {count} ({count/len(outcomes)*100:.1f}%)\")\n",
    "\n",
    "# Success categories (simplified view)\n",
    "print(\"\\nðŸ“ˆ INTERVENTION SUCCESS CATEGORIES:\")\n",
    "category_counts = Counter(o['success_category'] for o in outcomes)\n",
    "for category, count in category_counts.most_common():\n",
    "    print(f\"  â€¢ {category}: {count} ({count/len(outcomes)*100:.1f}%)\")\n",
    "\n",
    "# Assessment method distribution\n",
    "print(\"\\nðŸ” ASSESSMENT METHOD DISTRIBUTION:\")\n",
    "method_counts = Counter(o['assessment'].get('assessment_method', 'unknown') for o in outcomes)\n",
    "for method, count in method_counts.most_common():\n",
    "    print(f\"  â€¢ {method}: {count} ({count/len(outcomes)*100:.1f}%)\")\n",
    "\n",
    "# Show examples of successful interventions (if any)\n",
    "successful_studies = [o for o in outcomes if o['success_category'] == 'success']\n",
    "if successful_studies:\n",
    "    print(f\"\\nâœ… EXAMPLES OF SUCCESSFUL INTERVENTIONS ({len(successful_studies)} total):\")\n",
    "    for i, study in enumerate(successful_studies[:3]):\n",
    "        print(f\"{i+1}. {study['nct_id']}: {study['title'][:80]}...\")\n",
    "        print(f\"   Assessment: {study['assessment']['success']} (confidence: {study['assessment']['confidence']})\")\n",
    "        if study['assessment'].get('details'):\n",
    "            print(f\"   Details: {study['assessment']['details'][:100]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b4dbd",
   "metadata": {},
   "source": [
    "## Generate Prediction Market Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed99643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ² Generated 796 prediction market questions from 497 suitable studies\n",
      "ðŸ“Š Ratio: 1.6 questions per study on average\n",
      "\n",
      "ðŸ“‹ QUESTION TYPE BREAKDOWN:\n",
      "  â€¢ efficacy: 497 questions (62.4%)\n",
      "  â€¢ timeline: 256 questions (32.2%)\n",
      "  â€¢ replication: 43 questions (5.4%)\n",
      "\n",
      "ðŸ“ SAMPLE QUESTIONS BY TYPE AND CATEGORY:\n",
      "\n",
      "EFFICACY QUESTIONS (497 total):\n",
      "  [inconclusive] Will Fibit + Coaching improve Sleep Duration (Assess changes in sleep quality) at time points at visit 1 (week 1), visit 2 (week 6) and visit 3 (week 12) in Sleep for trial NCT04246424?\n",
      "    Status: COMPLETED | Assessment: COMPLETED_NO_RESULTS | Method: status_only\n",
      "    Details: Study completed but no results posted yet...\n",
      "\n",
      "  [inconclusive] Will ACT Intervention Group improve Change is being assessed using the Quality of Life BREF (WHOQOLBREFÍ¾ Skevington et al., 2004) questionnaire at Baseline and 6 weeks in Anxiety, Depression for trial NCT02449759?\n",
      "    Status: COMPLETED | Assessment: COMPLETED_NO_RESULTS | Method: status_only\n",
      "    Details: Study completed but no results posted yet...\n",
      "\n",
      "  [inconclusive] Will Family-Directed Cognitive Adaptation Program improve Social Adaptive Functions Scale (P) at Baseline, end of treatment, and 3 months after end of treatment, 6 months after end of treatment in Schizophrenia, Schizoaffective Disorder, Schizophreniform Disorder for trial NCT00434980?\n",
      "    Status: COMPLETED | Assessment: COMPLETED_NO_RESULTS | Method: status_only\n",
      "    Details: Study completed but no results posted yet...\n",
      "\n",
      "  [inconclusive] Will Prevention of hip fractures improve Survival at Maximum 21 years of follow up (Participants were on average 79 years old (70 to 100 years) at study start) in Fragility Fracture for trial NCT05269979?\n",
      "    Status: UNKNOWN | Assessment: INCONCLUSIVE | Method: status_only\n",
      "\n",
      "\n",
      "TIMELINE QUESTIONS (256 total):\n",
      "  [inconclusive] Will trial NCT04246424 post primary results on ClinicalTrials.gov within 12 months of completion?\n",
      "    Status: COMPLETED | Assessment: COMPLETED_NO_RESULTS | Method: status_only\n",
      "    Details: Study completed but no results posted yet...\n",
      "\n",
      "  [inconclusive] Will trial NCT02449759 post primary results on ClinicalTrials.gov within 12 months of completion?\n",
      "    Status: COMPLETED | Assessment: COMPLETED_NO_RESULTS | Method: status_only\n",
      "    Details: Study completed but no results posted yet...\n",
      "\n",
      "  [inconclusive] Will trial NCT00434980 post primary results on ClinicalTrials.gov within 12 months of completion?\n",
      "    Status: COMPLETED | Assessment: COMPLETED_NO_RESULTS | Method: status_only\n",
      "    Details: Study completed but no results posted yet...\n",
      "\n",
      "  [inconclusive] Will trial NCT03737279 post primary results on ClinicalTrials.gov within 12 months of completion?\n",
      "    Status: COMPLETED | Assessment: COMPLETED_NO_RESULTS | Method: status_only\n",
      "    Details: Study completed but no results posted yet...\n",
      "\n",
      "\n",
      "REPLICATION QUESTIONS (43 total):\n",
      "  [failure] If trial NCT03488927 were replicated with the same design, would it achieve the same outcome (failure)?\n",
      "    Status: COMPLETED | Assessment: FAILURE | Method: statistical_analysis\n",
      "    Details: 0/1 primary outcomes significant...\n",
      "\n",
      "  [success] If trial NCT03099369 were replicated with the same design, would it achieve the same outcome (success)?\n",
      "    Status: COMPLETED | Assessment: SUCCESS | Method: statistical_analysis\n",
      "    Details: 1/1 primary outcomes significant...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate prediction market questions from suitable studies\n",
    "# Create one question per primary outcome measure\n",
    "questions = []\n",
    "for outcome in outcomes:\n",
    "    if outcome['suitable_for_prediction']:\n",
    "        # Get the study data to access all primary outcomes\n",
    "        study_nct = outcome['nct_id']\n",
    "        study_data = next((s for s in studies if s.get('protocolSection', {}).get('identificationModule', {}).get('nctId') == study_nct), None)\n",
    "        \n",
    "        if study_data:\n",
    "            protocol_section = study_data.get('protocolSection', {})\n",
    "            primary_outcomes = protocol_section.get('outcomesModule', {}).get('primaryOutcomes', [])\n",
    "            conditions = protocol_section.get('conditionsModule', {}).get('conditions', [])\n",
    "            interventions = protocol_section.get('armsInterventionsModule', {}).get('interventions', [])\n",
    "            behavioral_interventions = [i for i in interventions if i.get('type') == 'BEHAVIORAL']\n",
    "            \n",
    "            # Base data for all questions from this study\n",
    "            base_data = {\n",
    "                'nct_id': outcome['nct_id'],\n",
    "                'title': outcome['title'],\n",
    "                'conditions': ', '.join(outcome['conditions']),\n",
    "                'study_status': outcome['assessment']['status'],\n",
    "                'success_assessment': outcome['assessment']['success'],\n",
    "                'success_category': outcome['success_category'],\n",
    "                'confidence': outcome['assessment']['confidence'],\n",
    "                'assessment_method': outcome['assessment'].get('assessment_method', 'unknown'),\n",
    "                'has_results': outcome['assessment']['has_results'],\n",
    "                'termination_reason': outcome['assessment'].get('termination_reason', ''),\n",
    "                'assessment_details': outcome['assessment'].get('details', ''),\n",
    "                'evidence_url': outcome['evidence_url'],\n",
    "                'question_type': 'efficacy'\n",
    "            }\n",
    "            \n",
    "            # Generate one question per primary outcome\n",
    "            if primary_outcomes and behavioral_interventions:\n",
    "                intervention_name = behavioral_interventions[0].get('name', 'the intervention')\n",
    "                condition_text = ', '.join(conditions) if conditions else 'participants'\n",
    "                \n",
    "                for i, primary_outcome in enumerate(primary_outcomes):\n",
    "                    measure = primary_outcome.get('measure', 'outcomes')\n",
    "                    timeframe = primary_outcome.get('timeFrame', 'study completion')\n",
    "                    \n",
    "                    # Create the question for this specific outcome\n",
    "                    question_text = f\"Will {intervention_name} improve {measure} at {timeframe} in {condition_text} for trial {outcome['nct_id']}?\"\n",
    "                    \n",
    "                    # Create a copy of base data for this question\n",
    "                    question_data = base_data.copy()\n",
    "                    question_data.update({\n",
    "                        'question': question_text,\n",
    "                        'primary_outcome_measure': measure,\n",
    "                        'primary_outcome_timeframe': timeframe,\n",
    "                        'outcome_number': i + 1,\n",
    "                        'total_primary_outcomes': len(primary_outcomes)\n",
    "                    })\n",
    "                    \n",
    "                    questions.append(question_data)\n",
    "            \n",
    "        # Fallback: if we can't access study data, use the single question we already generated\n",
    "        elif outcome['prediction_question']:\n",
    "            fallback_data = {\n",
    "                'nct_id': outcome['nct_id'],\n",
    "                'title': outcome['title'],\n",
    "                'question': outcome['prediction_question'],\n",
    "                'conditions': ', '.join(outcome['conditions']),\n",
    "                'study_status': outcome['assessment']['status'],\n",
    "                'success_assessment': outcome['assessment']['success'],\n",
    "                'success_category': outcome['success_category'],\n",
    "                'confidence': outcome['assessment']['confidence'],\n",
    "                'assessment_method': outcome['assessment'].get('assessment_method', 'unknown'),\n",
    "                'has_results': outcome['assessment']['has_results'],\n",
    "                'termination_reason': outcome['assessment'].get('termination_reason', ''),\n",
    "                'assessment_details': outcome['assessment'].get('details', ''),\n",
    "                'evidence_url': outcome['evidence_url'],\n",
    "                'question_type': 'efficacy',\n",
    "                'primary_outcome_measure': 'Unknown',\n",
    "                'primary_outcome_timeframe': 'Unknown',\n",
    "                'outcome_number': 1,\n",
    "                'total_primary_outcomes': 1\n",
    "            }\n",
    "            questions.append(fallback_data)\n",
    "\n",
    "print(f\"ðŸŽ² Generated {len(questions)} prediction market questions from {len([o for o in outcomes if o['suitable_for_prediction']])} suitable studies\")\n",
    "print(f\"ðŸ“Š Ratio: {len(questions)/len([o for o in outcomes if o['suitable_for_prediction']]):.1f} questions per study on average\")\n",
    "\n",
    "# Show breakdown by number of primary outcomes\n",
    "outcome_counts = Counter(q['total_primary_outcomes'] for q in questions)\n",
    "print(f\"\\nðŸ“‹ PRIMARY OUTCOMES PER STUDY:\")\n",
    "for outcome_count, freq in sorted(outcome_counts.items()):\n",
    "    studies_with_count = freq // outcome_count if outcome_count > 0 else freq\n",
    "    print(f\"  â€¢ {outcome_count} primary outcome(s): {studies_with_count} studies ({freq} questions)\")\n",
    "\n",
    "# Show sample questions grouped by study\n",
    "print(\"\\nðŸ“ SAMPLE QUESTIONS BY STUDY:\")\n",
    "questions_by_study = {}\n",
    "for q in questions:\n",
    "    nct_id = q['nct_id']\n",
    "    if nct_id not in questions_by_study:\n",
    "        questions_by_study[nct_id] = []\n",
    "    questions_by_study[nct_id].append(q)\n",
    "\n",
    "# Show first few studies with multiple outcomes\n",
    "multi_outcome_studies = [(nct, qs) for nct, qs in questions_by_study.items() if len(qs) > 1]\n",
    "single_outcome_studies = [(nct, qs) for nct, qs in questions_by_study.items() if len(qs) == 1]\n",
    "\n",
    "if multi_outcome_studies:\n",
    "    print(f\"\\nðŸŽ¯ STUDIES WITH MULTIPLE PRIMARY OUTCOMES ({len(multi_outcome_studies)} studies):\")\n",
    "    for i, (nct_id, study_questions) in enumerate(multi_outcome_studies[:2]):\n",
    "        print(f\"\\n{i+1}. Study {nct_id} ({len(study_questions)} primary outcomes):\")\n",
    "        print(f\"   Title: {study_questions[0]['title'][:60]}...\")\n",
    "        for j, q in enumerate(study_questions):\n",
    "            print(f\"   Outcome {j+1}: {q['primary_outcome_measure'][:50]}...\")\n",
    "            print(f\"     Question: {q['question'][:80]}...\")\n",
    "            print()\n",
    "\n",
    "if single_outcome_studies:\n",
    "    print(f\"ðŸ“ STUDIES WITH SINGLE PRIMARY OUTCOME ({len(single_outcome_studies)} studies):\")\n",
    "    for i, (nct_id, study_questions) in enumerate(single_outcome_studies[:2]):\n",
    "        q = study_questions[0]\n",
    "        print(f\"{i+1}. {nct_id}: {q['question'][:80]}...\")\n",
    "        print(f\"   Assessment: {q['success_assessment']} ({q['assessment_method']})\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd1c08",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Exported 796 questions to prediction_market_questions.csv\n",
      "\n",
      "ðŸŽ¯ FINAL SUMMARY:\n",
      "  â€¢ Fetched 500 behavioral intervention studies\n",
      "  â€¢ Found 497 studies suitable for prediction markets\n",
      "  â€¢ Generated 796 total prediction market questions\n",
      "  â€¢ Average: 1.6 questions per suitable study\n",
      "  â€¢ Question types: efficacy (497), timeline (256), replication (43)\n"
     ]
    }
   ],
   "source": [
    "# Export prediction market questions to CSV\n",
    "if questions:\n",
    "    filename = \"prediction_market_questions.csv\"\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = questions[0].keys()\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for question in questions:\n",
    "            writer.writerow(question)\n",
    "    \n",
    "    print(f\"âœ… Exported {len(questions)} questions to {filename}\")\n",
    "else:\n",
    "    print(\"âŒ No questions to export\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ FINAL SUMMARY:\")\n",
    "print(f\"  â€¢ Fetched {len(studies)} behavioral intervention studies\")\n",
    "print(f\"  â€¢ Found {len([o for o in outcomes if o['suitable_for_prediction']])} studies suitable for prediction markets\")\n",
    "print(f\"  â€¢ Generated {len(questions)} total prediction market questions\")\n",
    "print(f\"  â€¢ Average: {len(questions)/len([o for o in outcomes if o['suitable_for_prediction']]):.1f} questions per suitable study\")\n",
    "\n",
    "# Count studies by number of primary outcomes\n",
    "studies_with_multiple = len([nct for nct, qs in questions_by_study.items() if len(qs) > 1])\n",
    "studies_with_single = len([nct for nct, qs in questions_by_study.items() if len(qs) == 1])\n",
    "print(f\"  â€¢ Studies with multiple primary outcomes: {studies_with_multiple}\")\n",
    "print(f\"  â€¢ Studies with single primary outcome: {studies_with_single}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
